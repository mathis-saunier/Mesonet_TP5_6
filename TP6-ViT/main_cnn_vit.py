# -*- coding: utf-8 -*-
"""Main-CNN-ViT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_mBFhv8_TRmz4I744SaFsCL1NmYIo0D4
"""

import numpy as np

import sys
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import pickle
from tqdm import tqdm
import os
import editdistance
import datetime

import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import torchvision.transforms.functional as TF
import random

# Import the modified transformer file
import transformer_vit_dimitri as TRANSFORMER

# Setup logging and directory
now = datetime.datetime.now()
date_str = now.strftime("%Y%m%d_%H%M%S")
save_dir = f"CNN_ViT_{date_str}"
os.makedirs(save_dir, exist_ok=True)

class Logger(object):
    def __init__(self):
        self.terminal = sys.stdout
        self.log = open(os.path.join(save_dir, "log.txt"), "a")

    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)

    def flush(self):
        pass

sys.stdout = Logger()

def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def Load_MNISTSequences(file_name,config):
    ###########################################################################
    # on charge les dataset des séquence de train et de test
    print("Loading training and test data...")
    pkl_file = open(file_name, 'rb')
    x_train,yy_train, x_test,yy_test = pickle.load(pkl_file)
    pkl_file.close()

    y_train=[]
    y_test=[]

    #####################################################################
    # reformatage de la ground truth en string
    for n in range(len(yy_train)):
        GT = np.append(config['START_TOKEN'],np.append(yy_train[n].T[0][:],config['END_TOKEN']))
        y_train.append(torch.from_numpy(GT))
        # Normalisation des images [0, 1]
        x_train[n] = torch.from_numpy(np.float32(x_train[n])) / 255.0

    for n in range(len(yy_test)):
        GT = np.append(config['START_TOKEN'],np.append(yy_test[n].T[0][:],config['END_TOKEN']))
        y_test.append(torch.from_numpy(GT))
        # Normalisation des images [0, 1]
        x_test[n] = torch.from_numpy(np.float32(x_test[n])) / 255.0
    ###############################################################
    return x_train,x_test,y_train,y_test

##############################################################################
class DigitSequenceDataset(Dataset):
    """5 digits sequences MNIST datset."""

    def __init__(self, DATA, LABELS):
        """
        Arguments:
        """
        self.data = DATA
        self.labels = LABELS

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        return self.data[idx],self.labels[idx]
###############################################################
def pad_collate(batch):
  (xx, yy) = zip(*batch)
  x_lens = [len(x) for x in xx]
  y_lens = [len(y) for y in yy]

  x_lens = torch.LongTensor(x_lens)
  y_lens = torch.LongTensor(y_lens)
  
  # For CNN-ViT, xx are images (120x120), not sequences of patches
  # So we just stack them. They should all be same size.
  # xx is a tuple of tensors (120, 120)
  
  # Check if xx contains 2D tensors (images) or 3D tensors (patches)
  # In this script, we do NOT apply sliding window, so they are (120, 120)
  
  xx_pad = torch.stack(xx) # (Batch, 120, 120)
  
  yy_pad = torch.nn.utils.rnn.pad_sequence(yy, batch_first=True, padding_value=14) 

  return xx_pad[:,None,:,:], yy_pad, x_lens, y_lens

def augment_data(x_train, y_train):
    print("Augmenting data...")
    x_aug = []
    y_aug = []
    
    for i in range(len(x_train)):
        img = x_train[i].unsqueeze(0) # Add channel dim
        label = y_train[i]
        
        # Original
        x_aug.append(x_train[i])
        y_aug.append(label)
        
        # Rotate -10 to 10 degrees
        angle = random.uniform(-10, 10)
        img_rot = TF.rotate(img, angle)
        x_aug.append(img_rot.squeeze(0))
        y_aug.append(label)
        
    return x_aug, y_aug

if __name__ == '__main__':

    TRAINING = False  # Training if True Testing otherwise
    REPRISE = False
    SHOW = True

    device="cpu"
    if torch.backends.mps.is_available():
        device = torch.device("mps")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
    print("Device :",device)

    config = {
        'w_width':10, # Patch size for SimpleViTSequence
        'w_stride':30, # Not used
        'input_features':16, # Not used
        'max_length':225, # Not used
        'batch_size':512,
        'num_epochs':500,
        'hidden_size':128,
        'num_heads':4, 
        'num_layers':2,
        'learning_rate':1e-3, 
        'dropout':0.1, 
        'num_classes':15, 
        'x_pad_idx':-1, 
        'y_pad_idx':14, 

        'START_TOKEN':12, 
        'END_TOKEN':13,
    }
    
    data_file = 'MNIST_5digits2DHorizontalFacile.pkl'
    x_train,x_test,y_train,y_test = Load_MNISTSequences(data_file,config)
    N_train = len(y_train)

    l_seq_digits = 5
    D = 28 # 28 X 28

    N_max = 60000 # digits
    N_max_seq = int(N_max / l_seq_digits) # 60000 / 5 digits

    N_train = 54000 # digits 54000
    N_train_seq = int(N_train / l_seq_digits)
    END_TRAIN = N_train_seq 

    N_batch = int(N_train_seq / config['batch_size'])
    N_valid = 6000 #6000
    N_valid_seq = int(N_valid / l_seq_digits)
    START_VALID = N_max_seq - N_valid_seq  

    dir_name = ""
    
    model_name = dir_name+"SimpleViT_"+str(config['num_layers'])+"_"+str(config['hidden_size'])+"_"+str(config['num_heads'])+"_"+str(N_train)

    if TRAINING:
        
        # Data Augmentation
        x_train_aug, y_train_aug = augment_data(x_train[:N_train_seq], y_train[:N_train_seq])
        
        Train_seq_dataset = DigitSequenceDataset(x_train_aug, y_train_aug)
        train_dataloader = torch.utils.data.DataLoader(Train_seq_dataset,
                                                        batch_size = config['batch_size'],
                                                        shuffle=True,
                                                        collate_fn = pad_collate)

        ############### pour la VALID #################
        valid = x_train[N_max_seq - N_valid_seq:]
        gt_valid = y_train[N_max_seq - N_valid_seq:]
        Valid_seq_dataset = DigitSequenceDataset(valid,gt_valid)
        valid_dataloader = torch.utils.data.DataLoader(Valid_seq_dataset,
                                                       batch_size = config['batch_size'],
                                                       collate_fn = pad_collate)

        ###########################################################
        if SHOW:
            for batch in (train_dataloader):
                for i in range(5):
                    
                    plt.imshow(batch[0][i,0,:,:].numpy(), cmap='gray')
                    plt.title(batch[1][i,:])
                    plt.savefig(os.path.join(save_dir, f"batch_sample_{i}.png"))
                    plt.close()

                break
        ############################################################
        # apprentissage from scratch
        if not REPRISE:
            my_transformer = TRANSFORMER.SimpleViTSequence(config,device).to(device)
        else:
            # reprise de l'apprentissage 
            my_transformer = TRANSFORMER.SimpleViTSequence(config,device)
            my_transformer.load_state_dict(torch.load(model_name))
            my_transformer.to(device)
        
        # Optimizer and Scheduler
        optimizer = torch.optim.AdamW(my_transformer.parameters(), lr=config['learning_rate'], weight_decay=0.05)
        
        num_training_steps = len(train_dataloader) * config['num_epochs']
        num_warmup_steps = int(0.1 * num_training_steps)
        scheduler = TRANSFORMER.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)

        train_loss_history = []
        valid_loss_history = []
        
        best_valid_acc = 0.0
        
        for e in tqdm(range(config['num_epochs'])):
            train_loss, train_acc = TRANSFORMER.train_loop(train_dataloader,
                                                     my_transformer,
                                                     TRANSFORMER.sequence_loss,
                                                     optimizer,
                                                     scheduler)

            valid_loss, valid_acc, valid_seq_acc = TRANSFORMER.valid_loop(valid_dataloader,
                                                     my_transformer,
                                                     TRANSFORMER.sequence_loss)
            
            train_loss_history.append(train_loss)
            valid_loss_history.append(valid_loss)

            print(f"Epoch {e+1}/{config['num_epochs']} - Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Valid Loss: {valid_loss:.4f} Acc: {valid_acc:.4f} Seq Acc: {valid_seq_acc:.4f}")

            ###################################################################
            plt.plot(valid_loss_history,color = 'red', label = "valid")
            plt.plot(train_loss_history, color = 'blue', label = " train")
            plt.title("Transformer: Cross Ent. loss over epochs")
            plt.legend()
            plt.savefig(os.path.join(save_dir, "loss_curve.png"))
            plt.close()
            ###################################################################
            
            if valid_seq_acc > best_valid_acc:
                best_valid_acc = valid_seq_acc
                # on mémorise ce modèle
                torch.save(my_transformer.state_dict(), model_name)
                print(f"New best model saved with Seq Acc: {best_valid_acc:.4f}")

        print('Embedded Training Ended successfully')
        nb_train_param = count_parameters(my_transformer)
        print("Nombre de paramètres libres:",nb_train_param)
    else:
        ###########################################################################
        # Testing
        N_test_seq = len(x_test)
        Test_seq_dataset = DigitSequenceDataset(x_test,y_test)
        test_dataloader = torch.utils.data.DataLoader(Test_seq_dataset,
                                                      batch_size = config['batch_size'], # Can use batch size > 1 now
                                                      collate_fn = pad_collate)

        my_transformer = TRANSFORMER.SimpleViTSequence(config,device)
        my_transformer.load_state_dict(torch.load(model_name))
        my_transformer.to(device)
        
        digit_acc, seq_acc = TRANSFORMER.compute_accuracy(test_dataloader, my_transformer)
        
        cer = 1.0 - digit_acc
        ser = 1.0 - seq_acc

        print('Recognition ended successfully')
        print(f'Character Error Rate (CER): {cer*100:.2f}%')
        print(f'Character Recognition Rate (CRR): {digit_acc*100:.2f}%')
        print(f'Sequence Error Rate (SER): {ser*100:.2f}%')
        print(f'Sequence Recognition Rate (SRR): {seq_acc*100:.2f}%')
        print("Nombre de paramètres du modèle:",count_parameters(my_transformer))
