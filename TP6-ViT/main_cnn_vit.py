# -*- coding: utf-8 -*-
"""Main-CNN-ViT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_mBFhv8_TRmz4I744SaFsCL1NmYIo0D4
"""

import numpy as np

import sys
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import pickle
from tqdm import tqdm
import os
import editdistance
import datetime

import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import torchvision.transforms.functional as TF
import random

# Import the modified transformer file
import transformer_vit_dimitri as TRANSFORMER

# Setup logging and directory
now = datetime.datetime.now()
date_str = now.strftime("%Y%m%d_%H%M%S")
save_dir = f"CNN_ViT_{date_str}"
os.makedirs(save_dir, exist_ok=True)

class Logger(object):
    def __init__(self):
        self.terminal = sys.stdout
        self.log = open(os.path.join(save_dir, "log.txt"), "a")

    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)

    def flush(self):
        pass

sys.stdout = Logger()

def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def Load_MNISTSequences(file_name,config):
    ###########################################################################
    # on charge les dataset des séquence de train et de test
    print("Loading training and test data...")
    pkl_file = open(file_name, 'rb')
    x_train,yy_train, x_test,yy_test = pickle.load(pkl_file)
    pkl_file.close()

    y_train=[]
    y_test=[]

    #####################################################################
    # reformatage de la ground truth en string
    for n in range(len(yy_train)):
        GT = np.append(config['START_TOKEN'],np.append(yy_train[n].T[0][:],config['END_TOKEN']))
        y_train.append(torch.from_numpy(GT))
        # Normalisation des images [0, 1]
        x_train[n] = torch.from_numpy(np.float32(x_train[n])) / 255.0

    for n in range(len(yy_test)):
        GT = np.append(config['START_TOKEN'],np.append(yy_test[n].T[0][:],config['END_TOKEN']))
        y_test.append(torch.from_numpy(GT))
        # Normalisation des images [0, 1]
        x_test[n] = torch.from_numpy(np.float32(x_test[n])) / 255.0
    ###############################################################
    return x_train,x_test,y_train,y_test

##############################################################################
class DigitSequenceDataset(Dataset):
    """5 digits sequences MNIST datset."""

    def __init__(self, DATA, LABELS):
        """
        Arguments:
        """
        self.data = DATA
        self.labels = LABELS

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        return self.data[idx],self.labels[idx]
###############################################################
def pad_collate(batch):
  (xx, yy) = zip(*batch)
  x_lens = [len(x) for x in xx]
  y_lens = [len(y) for y in yy]

  x_lens = torch.LongTensor(x_lens)
  y_lens = torch.LongTensor(y_lens)
  
  # For CNN-ViT, xx are images (120x120), not sequences of patches
  # So we just stack them. They should all be same size.
  # xx is a tuple of tensors (120, 120)
  
  # Check if xx contains 2D tensors (images) or 3D tensors (patches)
  # In this script, we do NOT apply sliding window, so they are (120, 120)
  
  xx_pad = torch.stack(xx) # (Batch, 120, 120)
  
  yy_pad = torch.nn.utils.rnn.pad_sequence(yy, batch_first=True, padding_value=14) 

  return xx_pad[:,None,:,:], yy_pad, x_lens, y_lens

def augment_data(x_train, y_train):
    print("Augmenting data...")
    x_aug = []
    y_aug = []
    
    for i in range(len(x_train)):
        img = x_train[i].unsqueeze(0) # Add channel dim
        label = y_train[i]
        
        # Original
        x_aug.append(x_train[i])
        y_aug.append(label)
        
        # Rotate -10 to 10 degrees
        angle = random.uniform(-10, 10)
        img_rot = TF.rotate(img, angle)
        x_aug.append(img_rot.squeeze(0))
        y_aug.append(label)
        
    return x_aug, y_aug

if __name__ == '__main__':

    TRAINING = True  # Training if True Testing otherwise
    REPRISE = False
    SHOW = False

    device="cpu"
    if torch.backends.mps.is_available():
        device = torch.device("mps")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
    print("Device :",device)

    config = {
        'w_width':8, # Not used for sliding window, but maybe relevant for CNN structure if dynamic
        'w_stride':30,
        'input_features':16, # CNN output channels
        'max_length':225, # 15x15 feature map flattened
        'batch_size':64,
        'num_epochs':1000,
        'hidden_size':128,
        'num_heads':4, 
        'num_layers':6,
        'learning_rate':3e-4, 
        'dropout':0.1, 
        'num_classes':14, 
        'x_pad_idx':-1, 
        'y_pad_idx':14, 

        'START_TOKEN':12, 
        'END_TOKEN':13,
    }
    
    data_file = 'MNIST_5digits2DHorizontalFacile.pkl'
    x_train,x_test,y_train,y_test = Load_MNISTSequences(data_file,config)
    N_train = len(y_train)

    l_seq_digits = 5
    D = 28 # 28 X 28

    N_max = 60000 # digits
    N_max_seq = int(N_max / l_seq_digits) # 60000 / 5 digits

    N_train = 54 # digits 54000
    N_train_seq = int(N_train / l_seq_digits)
    END_TRAIN = N_train_seq 

    N_batch = int(N_train_seq / config['batch_size'])
    N_valid = 6 #6000
    N_valid_seq = int(N_valid / l_seq_digits)
    START_VALID = N_max_seq - N_valid_seq  

    dir_name = ""
    
    model_name = dir_name+"CNN_ViT_"+str(config['num_layers'])+"_"+str(config['hidden_size'])+"_"+str(config['num_heads'])+"_"+str(N_train)

    if TRAINING:
        
        # Data Augmentation
        x_train_aug, y_train_aug = augment_data(x_train[:N_train_seq], y_train[:N_train_seq])
        
        # NO Sliding Window here! We pass full images to CNN
        
        Train_seq_dataset = DigitSequenceDataset(x_train_aug, y_train_aug)
        train_dataloader = torch.utils.data.DataLoader(Train_seq_dataset,
                                                        batch_size = config['batch_size'],
                                                        shuffle=True,
                                                        collate_fn = pad_collate)

        ############### pour la VALID #################
        valid = x_train[N_max_seq - N_valid_seq:]
        # NO Sliding Window here either
        gt_valid = y_train[N_max_seq - N_valid_seq:]
        Valid_seq_dataset = DigitSequenceDataset(valid,gt_valid)
        valid_dataloader = torch.utils.data.DataLoader(Valid_seq_dataset,
                                                       batch_size = config['batch_size'],
                                                       collate_fn = pad_collate)

        ###########################################################
        if SHOW:
            for batch in (train_dataloader):
                for i in range(5):
                    
                    plt.imshow(batch[0][i,0,:,:].numpy(), cmap='gray')
                    plt.title(batch[1][i,:])
                    plt.savefig(os.path.join(save_dir, f"batch_sample_{i}.png"))
                    plt.close()

                break
        ############################################################
        # apprentissage from scratch
        if not REPRISE:
            my_transformer = TRANSFORMER.CNN_ViT(config,device).to(device)
        else:
            # reprise de l'apprentissage 
            my_transformer = TRANSFORMER.CNN_ViT(config,device)
            my_transformer.load_state_dict(torch.load(model_name))
            my_transformer.to(device)
        
        loss_fn = torch.nn.CrossEntropyLoss(ignore_index=config['y_pad_idx'], reduction='mean', label_smoothing=0.1)
        optimizer = torch.optim.Adam(my_transformer.parameters(),lr=config['learning_rate'])
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)

        train_loss = []
        valid_loss = []
        for e in tqdm(range(config['num_epochs'])):
            train_loss.append(TRANSFORMER.train_loop(train_dataloader,
                                                     my_transformer,
                                                     loss_fn,
                                                     optimizer))

            valid_loss.append(TRANSFORMER.valid_loop(valid_dataloader,
                                                     my_transformer,
                                                     loss_fn))
            
            scheduler.step(valid_loss[-1])

            if e == 0:
                valid_loss.append(valid_loss[0])
            ###################################################################
            plt.plot(valid_loss,color = 'red', label = "valid")
            plt.plot(train_loss, color = 'blue', label = " train")
            plt.title("Transformer: Cross Ent. loss over epochs")
            plt.legend()
            plt.savefig(os.path.join(save_dir, "loss_curve.png"))
            plt.close()
            ###################################################################
            if e == 0:
                best_valid_loss = valid_loss[0]
            else:
                if valid_loss[-1] < best_valid_loss:
                    best_valid_loss = valid_loss[-1]
                    # on mémorise ce modèle
                    best_iteration = e
                    torch.save(my_transformer.state_dict(), model_name)

        print('Embedded Training Ended successfully')
        nb_train_param = count_parameters(my_transformer)
        print("Nombre de paramètres libres:",nb_train_param)
    else:
        ###########################################################################
        # NO Sliding Window
        # x_test = Apply_SlidingWindow2D(x_test,config)
        N_test_seq = len(x_test)
        Test_seq_dataset = DigitSequenceDataset(x_test,y_test)
        test_dataloader = torch.utils.data.DataLoader(Test_seq_dataset,
                                                      batch_size = 1,
                                                      collate_fn = pad_collate)

        my_transformer = TRANSFORMER.CNN_ViT(config,device)
        my_transformer.load_state_dict(torch.load(model_name))
        my_transformer.to(device)
        
        TOTAL = 0
        FP =0
        String_FP = 0
        TP_orientation = 0
        
        # loop testing every test sample and computing the Character Rrror Rate (CER)
        print("Recognition in progress...")
        with torch.no_grad():

            for batch ,(X, y,X_l,y_l) in tqdm(enumerate(test_dataloader)):
                X = X.to(my_transformer.DEVICE)
                
                ###### formate la gt en string ##########################
                y = y[0].numpy()[1:-1]
                if y[0] == 10:
                    y = ''.join([str(y[i]) for i in range(1,y.shape[0])])
                    y = 'H'+y
                elif  y[0] == 11:
                    y = ''.join([str(y[i]) for i in range(1,y.shape[0])])
                    y = 'V'+y
                    
                src_padding_mask = (X[:,:,0] == config['x_pad_idx']).to(
                    my_transformer.DEVICE)
                
                y_input = torch.tensor([[config['START_TOKEN']]], dtype=torch.long).to(
                    my_transformer.DEVICE)

                # iterative decoding stage symbol by symbol
                # on each test example : batch size is 1
                # stop at max_length
                for _ in range(config['max_length']):
                    pred = my_transformer(X.float(),y_input,
                                          y_output_mask = None,
                                          src_key_padding_mask=src_padding_mask,
                                          tgt_key_padding_mask = None)
                    next_output = pred.topk(1)[1].view(-1)[-1].item() # num with highest probability
                    next_output = torch.tensor([[next_output]]).to(
                        my_transformer.DEVICE)

                    # Concatenate previous input with predicted best word
                    y_input = torch.cat((y_input, next_output), dim=1)

                    if next_output[0,0] == config['END_TOKEN'] :
                        break
                
                best_sequence = y_input.to('cpu')[0].numpy()[1:-1]
                if best_sequence[0] == 10:
                    bs = ''.join([str(best_sequence[i]) for i in range(1,best_sequence.shape[0])])
                    bs = 'H'+bs
                elif best_sequence[0] == 11:
                    bs = ''.join([str(best_sequence[i]) for i in range(1,best_sequence.shape[0])])
                    bs = 'V'+bs
                    
                Edit_dist = editdistance.eval(y[1:],bs[1:])
                if SHOW:
                    print("y :",y,"bs :",bs)
                FP += Edit_dist
                TOTAL += len(y[1:])
                
                if y[0]==bs[0]:
                    TP_orientation +=1
                
                if Edit_dist !=0:
                    String_FP +=1
                

        print("FP",FP)
        print("TOTAL characters",TOTAL)
        print("String FP",String_FP)
        print("TOTAL strings",N_test_seq)
        print("TP_orientation",TP_orientation)
        print('Recognition ended successfully, Character Error Rate = ',FP/TOTAL*100,'%')
        print('                              , Character Recognition Rate = ',(1-FP/TOTAL)*100,'%')
        print('                              , String Error Rate    = ',String_FP/N_test_seq*100,'%')
        print('                              , String Recognition Rate    = ',(1-String_FP/N_test_seq)*100,'%')
        print('                              , Orientation Recocognition Rate = ', (TP_orientation/N_test_seq)*100,'%')
        print("Nombre de paramètres du modèle:",count_parameters(my_transformer))
