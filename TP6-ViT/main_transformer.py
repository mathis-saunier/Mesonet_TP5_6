# -*- coding: utf-8 -*-
"""Main-Transformer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_mBFhv8_TRmz4I744SaFsCL1NmYIo0D4
"""

import numpy as np

import sys
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import pickle
from tqdm import tqdm
import os
import editdistance
import datetime

import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader

# from google.colab import drive
# !mkdir -p drive
# drive.mount('/content/drive',force_remount=True)
# #!cd /content/drive/MyDrive/ColabNotebooks
# sys.path.append('/content/drive/MyDrive/ColabNotebooks')

import TRANSFORMER

# Setup logging and directory
now = datetime.datetime.now()
date_str = now.strftime("%Y%m%d_%H%M%S")
save_dir = f"ViT_{date_str}"
os.makedirs(save_dir, exist_ok=True)

class Logger(object):
    def __init__(self):
        self.terminal = sys.stdout
        self.log = open(os.path.join(save_dir, "log.txt"), "a")

    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)

    def flush(self):
        pass

sys.stdout = Logger()

def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def Load_MNISTSequences(file_name,config):
    ###########################################################################
    # on charge les dataset des séquence de train et de test
    print("Loading training and test data...")
    pkl_file = open(file_name, 'rb')
    x_train,yy_train, x_test,yy_test = pickle.load(pkl_file)
    pkl_file.close()

    y_train=[]
    y_test=[]

    #####################################################################
    # reformatage de la ground truth en string
    for n in range(len(yy_train)):
        GT = np.append(config['START_TOKEN'],np.append(yy_train[n].T[0][:],config['END_TOKEN']))
        y_train.append(torch.from_numpy(GT))
        x_train[n] = torch.from_numpy(np.float32(x_train[n]))

    for n in range(len(yy_test)):
        GT = np.append(config['START_TOKEN'],np.append(yy_test[n].T[0][:],config['END_TOKEN']))
        y_test.append(torch.from_numpy(GT))
        x_test[n] = torch.from_numpy(np.float32(x_test[n]))
    ###############################################################
    return x_train,x_test,y_train,y_test

##############################################################################
class DigitSequenceDataset(Dataset):
    """5 digits sequences MNIST datset."""

    def __init__(self, DATA, LABELS):
        """
        Arguments:
        """
        self.data = DATA
        self.labels = LABELS

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        return self.data[idx],self.labels[idx]
###############################################################
def pad_collate(batch):
  (xx, yy) = zip(*batch)
  x_lens = [len(x) for x in xx]
  y_lens = [len(y) for y in yy]

  x_lens = torch.LongTensor(x_lens)
  y_lens = torch.LongTensor(y_lens)
  xx_pad = torch.nn.utils.rnn.pad_sequence(xx, batch_first=True, padding_value=-1)
  yy_pad = torch.nn.utils.rnn.pad_sequence(yy, batch_first=True, padding_value=14) # on padera à 14 0-9 +HORIZ(10) + VERT(11) +START(12)+END(13)  14= Token de padding sur les sorties de la GT

  return xx_pad[:,None,:,:], yy_pad, x_lens, y_lens

###############################################################
def SlidingWindow2D(x,w_width):
  # pour remettre les images de lignes horizontales
  
  (Hauteur,Largeur) = x.shape
  HHauteur = int(Hauteur / w_width)
  LLargeur = int(Largeur / w_width)
  norm = w_width * w_width

  feature = np.zeros((HHauteur,LLargeur,norm))
  begin_vert = 0
  for h in range(HHauteur):
      end_vert = begin_vert + w_width
      begin_hori = 0
      for l in range(LLargeur):
          end_hori = begin_hori + w_width
          feature[h,l,:] = x[begin_vert:end_vert,begin_hori:end_hori].reshape((norm))
          begin_hori = end_hori
      begin_vert = end_vert
      
  # on serialise les patch ce qui interdit de traiter des images de taille différentes 
  # car la gestion du positionnal encoding 2D ne serait pas possible comme cela

  feature = feature.reshape((HHauteur*LLargeur,norm)) 

  return torch.from_numpy(np.float32(feature))#/norm))
##############################################################################
# extraction d'une fenetre glissante sur les images d'entrée
def Apply_SlidingWindow2D(x,config):
    xx=[]

    for n in range(len(x)):
        xx = xx + [SlidingWindow2D(x[n],config['w_width'])]

    for i in range(5):
        plt.imshow(x[i].numpy(), cmap='gray')
        plt.savefig(os.path.join(save_dir, f"input_{i}.png"))
        plt.close()
        plt.imshow(xx[i].numpy(), cmap='gray')
        plt.savefig(os.path.join(save_dir, f"patches_{i}.png"))
        plt.close()

    return xx

if __name__ == '__main__':

    TRAINING = True  # Training if True Testing otherwise
    REPRISE = False
    SHOW = False

    device="cpu"
    if torch.backends.mps.is_available():
        device = torch.device("mps")
    elif torch.cuda.is_available():
        device = torch.device("cuda")
    print("Device :",device)

    config = {
        'w_width':4, #5,
        'w_stride':30,#3, # 3, 5
        'input_features':16, # 25 26 49 64 81 100 
                             # 121 144 169 196 225 256
        'max_length':30, # 120 / w_width pour des images toutes de même taille 120 X 120
        'batch_size':64,
        'num_epochs':1000,
        'hidden_size':128,
        'num_heads':2,
        'num_layers':6,
        'learning_rate':1.0e-4,
        'dropout':0.4,
        'num_classes':14, # START_TOKEN + END_TOKEN + HORI + VERT
        'x_pad_idx':-1, # pour padder les entrées
        'y_pad_idx':14, # pour padder la GT = TOKEN DE PADDING 

        'START_TOKEN':12, # 10 = Horizontal 11 = Vertical
        'END_TOKEN':13,
    }
    #data_file = 'MNIST_5digitsDifficile.pkl' 
    #data_file = 'MNIST_5digits2DHorizontal.pkl'
    #data_file =  MNIST_5digits2DVertical.pkl' 
    data_file = 'MNIST_5digits2DHorizontalFacile.pkl'
    x_train,x_test,y_train,y_test = Load_MNISTSequences(data_file,config)
    N_train = len(y_train)

    l_seq_digits = 5
    D = 28 # 28 X 28

    N_max = 60000 # digits
    N_max_seq = int(N_max / l_seq_digits) # 60000 / 5 digits

    N_train = 54000 # digits 54000
    N_train_seq = int(N_train / l_seq_digits)
    END_TRAIN = N_train_seq # 90% 10 000 digits = 5 X 2000

    N_batch = int(N_train_seq / config['batch_size'])
    N_valid = 6000 #6000
    N_valid_seq = int(N_valid / l_seq_digits)
    START_VALID = N_max_seq - N_valid_seq  # 10% for validation 1000 digits = 5 X 200

    #dir_name = "/content/sample_data/"
    dir_name = ""
    
    model_name = dir_name+"ViT_"+str(config['num_layers'])+"_"+str(config['hidden_size'])+"_"+str(config['num_heads'])+"_"+str(N_train)

    if TRAINING:
        # On crée les dataloarder de pytorch pour géréer les lots de séquences
        # car on ne peut plus mettre les séquences bout à bout puisqu'on entaine
        # des réseaux récurrentsou des CNN qui exploitent le contexte
        # pour le TRAIN
        x_train = Apply_SlidingWindow2D(x_train,config)
        
        train = x_train[:N_train_seq]
        gt_train = y_train[:N_train_seq]
        Train_seq_dataset = DigitSequenceDataset(train,gt_train)
        train_dataloader = torch.utils.data.DataLoader(Train_seq_dataset,
                                                        batch_size = config['batch_size'],
                                                        shuffle=True,
                                                        collate_fn = pad_collate)

        ############### pour la VALID #################
        valid = x_train[N_max_seq - N_valid_seq:]
        gt_valid = y_train[N_max_seq - N_valid_seq:]
        Valid_seq_dataset = DigitSequenceDataset(valid,gt_valid)
        valid_dataloader = torch.utils.data.DataLoader(Valid_seq_dataset,
                                                       batch_size = config['batch_size'],
                                                       collate_fn = pad_collate)

        ###########################################################
        if SHOW:
            for batch in (train_dataloader):
                for i in range(5):
                    
                    plt.imshow(batch[0][i,0,:,:].numpy(), cmap='gray')
                    plt.title(batch[1][i,:])
                    plt.savefig(os.path.join(save_dir, f"batch_sample_{i}.png"))
                    plt.close()

                break
        ############################################################
        # apprentissage from scratch
        if not REPRISE:
            my_transformer = TRANSFORMER.ViTTransformer(config,device).to(device)
        else:
            # reprise de l'apprentissage 
            my_transformer = TRANSFORMER.ViTTransformer(config,device)
            my_transformer.load_state_dict(torch.load(model_name))
            my_transformer.to(device)
        
        loss_fn = torch.nn.CrossEntropyLoss(ignore_index=config['y_pad_idx'],reduction='mean')
        optimizer = torch.optim.Adam(my_transformer.parameters(),lr=config['learning_rate'])

        train_loss = []
        valid_loss = []
        for e in tqdm(range(config['num_epochs'])):
            train_loss.append(TRANSFORMER.train_loop(train_dataloader,
                                                     my_transformer,
                                                     loss_fn,
                                                     optimizer))

            valid_loss.append(TRANSFORMER.valid_loop(valid_dataloader,
                                                     my_transformer,
                                                     loss_fn))
            if e == 0:
                valid_loss.append(valid_loss[0])
            ###################################################################
            plt.plot(valid_loss,color = 'red', label = "valid")
            plt.plot(train_loss, color = 'blue', label = " train")
            plt.title("Transformer: Cross Ent. loss over epochs")
            plt.legend()
            plt.savefig(os.path.join(save_dir, "loss_curve.png"))
            plt.close()
            ###################################################################
            if e == 0:
                best_valid_loss = valid_loss[0]
            else:
                if valid_loss[-1] < best_valid_loss:
                    best_valid_loss = valid_loss[-1]
                    # on mémorise ce modèle
                    best_iteration = e
                    torch.save(my_transformer.state_dict(), model_name)

        print('Embedded Training Ended successfully')
        nb_train_param = count_parameters(my_transformer)
        print("Nombre de paramètres libres:",nb_train_param)
    else:
        ###########################################################################
        x_test = Apply_SlidingWindow2D(x_test,config)
        N_test_seq = len(x_test)
        Test_seq_dataset = DigitSequenceDataset(x_test,y_test)
        test_dataloader = torch.utils.data.DataLoader(Test_seq_dataset,
                                                      batch_size = 1,
                                                      collate_fn = pad_collate)

        my_transformer = TRANSFORMER.ViTTransformer(config,device)
        my_transformer.load_state_dict(torch.load(model_name))
        my_transformer.to(device)
        
        TOTAL = 0
        FP =0
        String_FP = 0
        TP_orientation = 0
        
        # loop testing every test sample and computing the Character Rrror Rate (CER)
        print("Recognition in progress...")
        with torch.no_grad():

            for batch ,(X, y,X_l,y_l) in tqdm(enumerate(test_dataloader)):
                X = X.to(my_transformer.DEVICE)
                
                ###### formate la gt en string ##########################
                y = y[0].numpy()[1:-1]
                if y[0] == 10:
                    y = ''.join([str(y[i]) for i in range(1,y.shape[0])])
                    y = 'H'+y
                elif  y[0] == 11:
                    y = ''.join([str(y[i]) for i in range(1,y.shape[0])])
                    y = 'V'+y
                    
                src_padding_mask = (X[:,:,0] == config['x_pad_idx']).to(
                    my_transformer.DEVICE)
                
                y_input = torch.tensor([[config['START_TOKEN']]], dtype=torch.long).to(
                    my_transformer.DEVICE)

                # iterative decoding stage symbol by symbol
                # on each test example : batch size is 1
                # stop at max_length
                for _ in range(config['max_length']):
                    pred = my_transformer(X.float(),y_input,
                                          y_output_mask = None,
                                          src_key_padding_mask=src_padding_mask,
                                          tgt_key_padding_mask = None)
                    next_output = pred.topk(1)[1].view(-1)[-1].item() # num with highest probability
                    next_output = torch.tensor([[next_output]]).to(
                        my_transformer.DEVICE)

                    # Concatenate previous input with predicted best word
                    y_input = torch.cat((y_input, next_output), dim=1)

                    if next_output[0,0] == config['END_TOKEN'] :
                        break
                
                best_sequence = y_input.to('cpu')[0].numpy()[1:-1]
                if best_sequence[0] == 10:
                    bs = ''.join([str(best_sequence[i]) for i in range(1,best_sequence.shape[0])])
                    bs = 'H'+bs
                elif best_sequence[0] == 11:
                    bs = ''.join([str(best_sequence[i]) for i in range(1,best_sequence.shape[0])])
                    bs = 'V'+bs
                    
                Edit_dist = editdistance.eval(y[1:],bs[1:])
                if SHOW:
                    print("y :",y,"bs :",bs)
                FP += Edit_dist
                TOTAL += len(y[1:])
                
                if y[0]==bs[0]:
                    TP_orientation +=1
                
                if Edit_dist !=0:
                    String_FP +=1
                

        print("FP",FP)
        print("TOTAL characters",TOTAL)
        print("String FP",String_FP)
        print("TOTAL strings",N_test_seq)
        print("TP_orientation",TP_orientation)
        print('Recognition ended successfully, Character Error Rate = ',FP/TOTAL*100,'%')
        print('                              , Character Recognition Rate = ',(1-FP/TOTAL)*100,'%')
        print('                              , String Error Rate    = ',String_FP/N_test_seq*100,'%')
        print('                              , String Recognition Rate    = ',(1-String_FP/N_test_seq)*100,'%')
        print('                              , Orientation Recocognition Rate = ', (TP_orientation/N_test_seq)*100,'%')
        print("Nombre de paramètres du modèle:",count_parameters(my_transformer))